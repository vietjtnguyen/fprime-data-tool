#!/usr/bin/env python3
import enum
import io
import struct


def as_json_obj_helper(obj, keys, fprime_dict=None, extended_dict=None):
    attrs = list(
        f'"{key}": {getattr(obj, key).as_json(fprime_dict)}'
        for key in keys)
    if extended_dict:
        attrs.extend(
            f'"{key}": {value}'
            for key, value in extended_dict.items())
    return '{' + ', '.join(attrs) + '}'


# Collection of serializaable types used in processing data for a given
# topology by their name.  If a dictionary is loaded the types defined there in
# will be added to this collection.
fp_types = {}
def register_fp_types(name=None):
    def register_fp_types_decorator(cls):
        fp_types_custom[name or cls.__name__] = cls
        return cls
    return register_fp_types_decorator


# Collection of serializable types defined for processing in this script that
# are not supposed to participate in processing topology types.
fp_types_custom = {}
def register_fp_types_custom(name=None):
    def register_fp_types_custom_decorator(cls):
        fp_types_custom[name or cls.__name__] = cls
        return cls
    return register_fp_types_custom_decorator


# Class decorator factory for extending an enum.IntEnum based class with an
# decode class function and encode method based on the provided underlying
# type.
def enum_represented_as(enum_underlying_type):
    def decorator(type):
        def decode(cls, istream):
            untyped = enum_underlying_type.decode(istream)
            return cls(untyped.value)
        type.decode = classmethod(decode)

        def encode(self, ostream):
            untyped = enum_underlying_type(self.value)
            untyped.encode(ostream)
        type.encode = encode

        def as_json(self, fprime_dict=None):
            return f'"{self.name}"'
        type.as_json = as_json

        return type

    return decorator


#### Fundamental types ---------------------------------------------------------


# Creates a class representing the fundamental type given the name and struct
# format.
def make_fundamental_type(name, struct_format):
    fundamental_struct = struct.Struct(struct_format)

    class FundamentalType():

        def __init__(self, value = 0):
            self.value = value

        @classmethod
        def decode(cls, istream):
            data = istream.read(fundamental_struct.size)
            return cls(fundamental_struct.unpack(data)[0])

        def encode(self, ostream):
            return ostream.write(fundamental_struct.pack(self.value))

        def as_json(self, fprime_dict=None):
            return str(self.value)

        def __float__(self):
            return float(self.value)

        def __format__(self, spec):
            return format(self.value, spec)

        def __int__(self):
            return int(self.value)

        def __repr__(self):
            return repr(self.value)

        def __str__(self):
            return str(self.value)

    FundamentalType.__name__ = name

    return FundamentalType


# Specification for fundamental_types.  Instead of manually writing out the
# types we construct them from this specification which is a tuple of name and
# struct format.
fundamental_type_specs = (
    ('I8', '>b'),
    ('U8', '>B'),
    ('I16', '>h'),
    ('U16', '>H'),
    ('I32', '>i'),
    ('U32', '>I'),
    ('I64', '>q'),
    ('U64', '>Q'),
    ('F32', '>f'),
    ('F64', '>d'),
)
fptypes_fundamental = {}
for name, struct_format in fundamental_type_specs:
    # Create the fundamental type and register it in fp_types.
    fp_types[name] = make_fundamental_type(name, struct_format)
    # Also collect the fundamental_types into their own collection.
    fptypes_fundamental[name] = fp_types[name]
    # Also put the fundamental_types into the global namespace for convenience.
    globals()[name] = fp_types[name]


#### F Prime configuration -----------------------------------------------------


# These are F Prime configuration flags (preprocessor definitions) that affect
# the format of data to be encoded/decoded.
fprime_configurable_flags = (
    # This controls whether the Time type includes the time base.
    ('FW_USE_TIME_BASE', True),
    # This controls whether the Time type includes the time context.
    ('FW_USE_TIME_CONTEXT', True),
)
for name, value in fprime_configurable_flags:
    # Put these flags in the global namespace for convenience.
    globals()[name] = value


# Another part of F Prime configuration is defining what fundamental types
# represent various things.  The following are the default type definitions.
# We also use this list to allow users to override using command line
# arguments.
fprime_configurable_types = (
    ('FwTimeBaseStoreType', U16),
    ('FwTimeContextStoreType', U8),
    ('FwPacketDescriptorType', U32),
    ('FwOpcodeType', U32),
    ('FwChanIdType', U32),
    ('FwEventIdType', U32),
    ('FwPrmIdType', U32),
    ('FwTlmPacketizeIdType', U16),
)
for name, value in fprime_configurable_types:
    # Define these types aliases in fp_types so they can be retrieved by name.
    fp_types[name] = value
    # Also put the type alias into the global namespace for convenience.
    globals()[name] = value


#### Basic non-fundamental types -----------------------------------------------


@register_fp_types_custom()
class Buffer():

    def __init__(self, data=b''):
        self.data = data

    def as_json(self, fprime_dict=None):
        return f'"0x{self.data.hex()}"'

    @classmethod
    def decode(cls, istream, length=None):
        '''
        Decodes a buffer object from the binary input stream by simply reading
        the data from the input stream as a bytes object and storing it in the
        `data` member.  If `length` is not specified then all of the remaining
        bytes in the binary input stream are read into the Buffer object.  This
        is "read the rest" behavior.  If length is specified then only that
        many bytes are read from the input stream.
        '''
        self = cls()
        self.data = istream.read(length)
        return self

    def encode(self, ostream):
        assert(type(self.data) is bytes)
        ostream.write(self.data)

    def __bytes__(self):
        return bytes(self.data)

    def __len__(self):
        return len(self.data)

    def __repr__(self):
        return repr(self.data)

    def __str__(self):
        return str(self.data)


@register_fp_types_custom()
class AsciiString():

    def __init__(self, string=b''):
        self.string = string

    def as_json(self, fprime_dict=None):
        return f'"{self.string}"'

    @classmethod
    def decode(cls, istream, length=None):
        '''
        Decodes an ASCII string object from the binary input stream by simply
        reading the string from the input stream as a bytes object, decoding it
        as an ASCII string, and storing it in the `string` member.  If `length`
        is not specified then all of the remaining bytes in the binary input
        stream are read into the AsciiString object.  This is "read the rest"
        behavior.  If length is specified then only that many bytes are read
        from the input stream.
        '''
        self = cls()
        self.string = istream.read(length).decode('ascii')
        return self

    def encode(self, ostream):
        assert(type(self.string) is string)
        ostream.write(self.string.encode('ascii'))

    def __bytes__(self):
        return bytes(self.string)

    def __len__(self):
        return len(self.string)

    def __repr__(self):
        return repr(self.string)

    def __str__(self):
        return str(self.string)


@register_fp_types()
@register_fp_types_custom()
class Time():

    def as_json(self, fprime_dict=None):
        import datetime
        unix_seconds = float(self.seconds) + float(self.microseconds) * 1e-6
        utc_datetime = datetime.datetime.utcfromtimestamp(unix_seconds)
        local_tzinfo = datetime.datetime.now().astimezone().tzinfo
        local_datetime = \
            datetime.datetime.fromtimestamp(unix_seconds, local_tzinfo )
        extended_dict = {
            'value': f'{unix_seconds}',
            'utc_year': f'"{utc_datetime.year}"',
            'utc_month': f'"{utc_datetime.month}"',
            'utc_day': f'"{utc_datetime.day}"',
            'utc_hour': f'"{utc_datetime.hour}"',
            'utc_minute': f'"{utc_datetime.minute}"',
            'utc_second': f'"{utc_datetime.second}"',
            'utc_microsecond': f'"{utc_datetime.microsecond}"',
            'utc_iso8601': f'"{utc_datetime.isoformat()}"',
            'local_year': f'"{local_datetime.year}"',
            'local_month': f'"{local_datetime.month}"',
            'local_day': f'"{local_datetime.day}"',
            'local_hour': f'"{local_datetime.hour}"',
            'local_minute': f'"{local_datetime.minute}"',
            'local_second': f'"{local_datetime.second}"',
            'local_microsecond': f'"{local_datetime.microsecond}"',
            'local_iso8601': f'"{local_datetime.isoformat()}"',
        }
        return as_json_obj_helper(
            self,
            ('base', 'context', 'seconds', 'microseconds'),
            fprime_dict,
            extended_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        if FW_USE_TIME_BASE:
            self.base = FwTimeBaseStoreType.decode(istream)
        if FW_USE_TIME_CONTEXT:
            self.context = FwTimeContextStoreType.decode(istream)
        self.seconds = U32.decode(istream)
        self.microseconds = U32.decode(istream)
        return self

    def encode(self, ostream):
        if FW_USE_TIME_BASE:
            assert(type(self.base) is FwTimeBaseStoreType)
        if FW_USE_TIME_CONTEXT:
            assert(type(self.context) is FwTimeContextStoreType)
        assert(type(self.seconds) is U32)
        assert(type(self.microseconds) is U32)
        if FW_USE_TIME_BASE:
            self.base.encode(ostream)
        if FW_USE_TIME_CONTEXT:
            self.context.encode(ostream)
        self.seconds = U32.decode(ostream)
        self.microseconds = U32.decode(ostream)

    def __str__(self):
        return str(float(self.seconds) + float(self.microseconds) * 1e-6)


#### Record types --------------------------------------------------------------


def create_record_class(name, packet_size_type):
    PacketSizeType = packet_size_type

    @register_fp_types_custom(name)
    class Record():

        def as_json(self, fprime_dict=None):
            return as_json_obj_helper(
                self,
                ('packet_size', 'packet'),
                fprime_dict,
                extended_dict={
                    "offset": str(self.offset)
                })

        @classmethod
        def decode(cls, istream):
            self = cls()
            self.offset = istream.tell()
            self.packet_size = PacketSizeType.decode(istream)

            # We slice off the input stream into a buffer and create a new
            # input stream backed by that buffer to pass to the Packet parser.
            # We do this because some parsers nested underneath the Packet
            # parser will "read the rest" but without the size context here.
            # For example, the event and telemetry packet parsers do this. We
            # use the size context here to limit the rest of the record so that
            # "read the rest" behavior underneath works as expected and doesn't
            # read the rest of the input stream.
            packet_buffer = istream.read(self.packet_size.value)
            self.packet = Packet.decode(io.BytesIO(packet_buffer))

            return self

        def encode(self, ostream):
            assert(type(self.packet_size) is packet_size_type)
            # TODO (vnguyen): Be smart about automatically calculating this.
            self.packet_size.encode(ostream)
            self.packet.encode(ostream)

    Record.__name__ = name
    return Record


ComLoggerRecord = create_record_class("ComLoggerRecord", U16)
FprimeGdsRecord = create_record_class("FprimeGdsRecord", U32)


#### F Prime packet types ------------------------------------------------------


@register_fp_types_custom()
class Packet():

    @enum_represented_as(FwPacketDescriptorType)
    @register_fp_types_custom('Packet.Type')
    class Type(enum.IntEnum):
        COMMAND = 0
        TELEM = 1
        LOG = 2
        FILE = 3
        PACKETIZED_TLM = 4
        IDLE = 5
        UNKNOWN = 0xFF

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(self, ('type', 'payload'), fprime_dict)

    @classmethod
    def decode(cls, istream):
        '''
        Decodes an F Prime packet (basically a `Fw::ComPacket`) from the given
        binary input stream.  This decoding process has "read the rest"
        behavior since size information is not a part of the packet itself.
        Thus it is important that the binary input stream is confined to the
        actual contents of the packet.  One way to do this is reading the
        packet as a whole (given packet size from a larger context) and
        wrapping that bytes object in a binary input stream using `io.BytesIO`.
        '''
        self = cls()
        self.type = type(self).Type.decode(istream)
        if self.type == type(self).Type.TELEM:
            self.payload = TelemPacket.decode(istream)
        elif self.type == type(self).Type.LOG:
            self.payload = EventPacket.decode(istream)
        elif self.type == type(self).Type.FILE:
            self.payload = FilePacket.decode(istream)
        else:
            # NOTE: This is "read the rest" behavior so it is important that
            # the input stream be confined to the extents of the packet itself.
            self.payload = Buffer.decode(istream)
        return self

    def encode(self, ostream):
        assert(type(self.type) is type(self).Type)
        if self.type == type(self).Type.TELEM:
            assert(type(self.payload) is TelemPacket)
        elif self.type == type(self).Type.LOG:
            assert(type(self.payload) is EventPacket)
        elif self.type == type(self).Type.FILE:
            assert(type(self.payload) is FilePacket)
        else:
            assert(type(self.payload) is Buffer)
        self.type.encode(ostream)
        self.payload.encode(ostream)


@register_fp_types_custom()
class TelemPacket():

    def as_json(self, fprime_dict=None):
        extended_dict = {}
        if fprime_dict:
            channel = fprime_dict.channels_by_id[self.id.value]
            extended_dict['topology_name'] = f'"{channel.topology_name}"'
            extended_dict['component'] = f'"{channel.component}"'
            extended_dict['name'] = f'"{channel.name}"'
        return as_json_obj_helper(
            self,
            ('id', 'time', 'value'),
            fprime_dict,
            extended_dict=extended_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.id = FwChanIdType.decode(istream)
        self.time = Time.decode(istream)
        # NOTE: This is "read the rest" behavior so it is important that the
        # input stream be confined to the extents of the packet itself.
        self.value = Buffer.decode(istream)
        return self

    def encode(self, ostream):
        assert(type(self.id) == FwChanIdType)
        assert(type(self.time) == Time)
        assert(type(self.value) == Buffer)
        self.id.encode(ostream)
        self.time.encode(ostream)
        self.value.encode(ostream)


@register_fp_types_custom()
class EventPacket():

    def as_json(self, fprime_dict=None):
        extended_dict = {}
        if fprime_dict:
            event = fprime_dict.events_by_id[self.id.value]
            extended_dict['topology_name'] = f'"{event.topology_name}"'
            extended_dict['component'] = f'"{event.component}"'
            extended_dict['name'] = f'"{event.name}"'
            extended_dict['severity'] = f'"{event.severity_str}"'
        return as_json_obj_helper(
            self,
            ('id', 'time', 'arguments'),
            fprime_dict,
            extended_dict=extended_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.id = FwEventIdType.decode(istream)
        self.time = Time.decode(istream)
        # NOTE: This is "read the rest" behavior so it is important that the
        # input stream be confined to the extents of the packet itself.
        self.arguments = Buffer.decode(istream)
        return self

    def encode(self, ostream):
        assert(type(self.id) == FwEventIdType)
        assert(type(self.time) == Time)
        assert(type(self.arguments) == Buffer)
        self.id.encode(ostream)
        self.time.encode(ostream)
        self.arguments.encode(ostream)


@register_fp_types_custom()
class FilePacketPathName():

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(self, ('length', 'value'), fprime_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.length = U8.decode(istream)
        self.value = AsciiString.decode(istream, self.length)
        return self

    def encode(self, ostream):
        assert(type(self.length) == U8)
        assert(type(self.value) == AsciiString)
        assert(len(self.value) == self.length)
        self.length.encode(ostream)
        self.value.encode(ostream)

    def __str__(self):
        return self.value.encode('ascii')


@register_fp_types_custom()
class FilePacket():

    @enum_represented_as(U8)
    @register_fp_types_custom('FilePacket.Type')
    class Type(enum.IntEnum):
        START = 0
        DATA = 1
        END = 2
        CANCEL = 3
        NONE = 255

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(
            self,
            ('type', 'sequence_index', 'payload'),
            fprime_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.type = type(self).Type.decode(istream)
        self.sequence_index = U32.decode(istream)

        if self.type == type(self).Type.START:
            self.payload = FilePacketStartPayload.decode(istream)
        elif self.type == type(self).Type.DATA:
            self.payload = FilePacketDataPayload.decode(istream)
        elif self.type == type(self).Type.END:
            self.payload = FilePacketEndPayload.decode(istream)
        elif self.type == type(self).Type.CANCEL:
            self.payload = FilePacketCancelPayload.decode(istream)
        else:
            raise KeyError(f'Encountered unknown FilePacket type: {self.type}')

        return self

    def encode(self, ostream):
        assert(type(self.type) is type(self).Type)
        assert(type(self.sequence_index) is U32)
        assert(len(self.value) == self.length)
        if self.type == type(self).Type.START:
            assert(type(self.payload) is FilePacketStartPayload)
        elif self.type == type(self).Type.DATA:
            assert(type(self.payload) is FilePacketDataPayload)
        elif self.type == type(self).Type.END:
            assert(type(self.payload) is FilePacketEndPayload)
        elif self.type == type(self).Type.CANCEL:
            assert(type(self.payload) is FilePacketCancelPayload)
        else:
            raise KeyError(f'Encountered unknown FilePacket type: {self.type}')
        self.type.encode(ostream)
        self.sequence_index.encode(ostream)
        self.payload.encode(ostream)


@register_fp_types_custom()
class FilePacketStartPayload():

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(
            self,
            ('file_size', 'source_path', 'destination_path'),
            fprime_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.file_size = U32.decode(istream)
        self.source_path = FilePacketPathName.decode(istream)
        self.destination_path = FilePacketPathName.decode(istream)
        return self

    def encode(self, ostream):
        self.file_size.encode(ostream)
        self.source_path.encode(ostream)
        self.destination_path.encode(ostream)


@register_fp_types_custom()
class FilePacketDataPayload():

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(
            self,
            ('byte_offset', 'data_size', 'data'),
            fprime_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.byte_offset = U32.decode(istream)
        self.data_size = U16.decode(istream)
        self.data = Buffer.decode(istream, self.data_size)
        return self

    def encode(self, ostream):
        assert(type(self.byte_offset) is U32)
        assert(type(self.data_size) is U16)
        assert(type(self.data) is Buffer)
        self.byte_offset.encode(ostream)
        self.data_size.encode(ostream)
        self.data.encode(ostream)


@register_fp_types_custom()
class FilePacketEndPayload():

    def as_json(self, fprime_dict=None):
        return as_json_obj_helper(self, ('checksum'), fprime_dict)

    @classmethod
    def decode(cls, istream):
        self = cls()
        self.checksum = U32.decode(istream)
        return self

    def encode(self, ostream):
        assert(type(self.checksum) is U32)
        self.checksum.encode(ostream)


@register_fp_types_custom()
class FilePacketCancelPayload():

    def as_json(self, fprime_dict=None):
        return '{}'

    @classmethod
    def decode(cls, istream):
        self = cls()
        return self

    def encode(self, ostream):
        pass


#### Dictionary ----------------------------------------------------------------


class FprimeDictionary():

    class Enum():

        class Item():

            def __init__(self, elem):
                self.name = elem.get('name')
                self.value_str = elem.get('value')
                self.value = int(self.value_str)
                self.description = elem.get('description')

        def __init__(self, elem):
            self.name = elem.get('type')
            self.items = [type(self).Item(x) for x in elem.findall('item')]

        def decode(self, istream):
            pass

    class Serializable():

        def decode(self, istream):
            pass

    class Array():

        def decode(self, istream):
            pass

    class Command():
        pass

    class Event():

        class Severity(enum.IntEnum):
            FATAL = 1
            WARNING_HI = 2
            WARNING_LO = 3
            COMMAND = 4
            ACTIVITY_HI = 5
            ACTIVITY_LO = 6
            DIAGNOSTIC = 7

        class Argument():

            def __init__(self, elem):
                self.name = elem.get('name')
                self.description = elem.get('description')
                self.length = int(elem.get('len')) if elem.get('len') else None
                self.type_str = elem.get('type')
                self.type = None

        def __init__(self, elem):
            self.component = elem.get('component')
            self.name = elem.get('name')
            self.topology_name = f'{self.component}.{self.name}'
            self.id_str = elem.get('id')
            self.id = int(
                self.id_str,
                base=16 if self.id_str.startswith('0x') else 10)
            self.severity_str = elem.get('severity')
            self.severity = type(self).Severity[self.severity_str]
            self.description = elem.get('description')
            self.format_string = elem.get('format_string')
            self.args = [
                type(self).Argument(x)
                for x in elem.find('args').findall('arg')]

    class Channel():

        def __init__(self, elem):
            self.component = elem.get('component')
            self.name = elem.get('name')
            self.topology_name = f'{self.component}.{self.name}'
            self.id_str = elem.get('id')
            self.id = int(
                self.id_str,
                base=16 if self.id_str.startswith('0x') else 10)
            self.format_string = elem.get('format_string')
            self.description = elem.get('description')
            self.type_str = elem.get('type')
            self.type = None

    class Parameter():
        pass

    def __init__(self, file_path):
        self.enums = {}
        self.serializables = {}
        self.arrays = {}
        self.commands = {}
        self.events = {}
        self.events_by_id = {}
        self.channels = {}
        self.channels_by_id = {}
        self.parameters = {}
        self.types = {}

        from xml.etree import ElementTree
        tree = ElementTree.parse(file_path)
        root = tree.getroot()
        for collection in root:
            if collection.tag == 'enums':
                for elem in collection:
                    if elem.tag == 'enum':
                        enum = type(self).Enum(elem)
                        self.enums[enum.name] = enum
            elif collection.tag == 'serializables':
                for elem in collection:
                    if elem.tag == 'serializable':
                        pass
            elif collection.tag == 'arrays':
                for elem in collection:
                    if elem.tag == 'array':
                        pass
            elif collection.tag == 'commands':
                for elem in collection:
                    if elem.tag == 'command':
                        pass
            elif collection.tag == 'events':
                for elem in collection:
                    if elem.tag == 'event':
                        event = type(self).Event(elem)
                        self.events[(event.component, event.name)] = event
                        self.events_by_id[event.id] = event
            elif collection.tag == 'channels':
                for elem in collection:
                    if elem.tag == 'channel':
                        channel = type(self).Channel(elem)
                        self.channels[(channel.component, channel.name)] = \
                            channel
                        self.channels_by_id[channel.id] = channel
            elif collection.tag == 'parameters':
                for elem in collection:
                    if elem.tag == 'parameter':
                        pass


#### Printers ------------------------------------------------------------------


class JsonPrinter():

    def __init__(self, fprime_dict=None):
        self._d = fprime_dict

    def print_header(self):
        pass

    def print_record(self, item):
        sys.stdout.write(f'{item.as_json(fprime_dict)}\n')

    def print_footer(self):
        pass

class TsvPrinter():

    def __init__(self, fprime_dict=None):
        self._d = fprime_dict

    def print_header(self):
        sys.stdout.write(
            'record_index'
            '\trecord_offset'
            '\tpacket_size'
            '\tpacket_type_name'
            '\tpacket_type_value'
            '\tpacket_time'
            '\ttelem_id'
            '\ttelem_id_hex'
            '\ttelem_topology_name'
            '\ttelem_component'
            '\ttelem_name'
            '\ttelem_time'
            '\ttelem_value_size'
            '\ttelem_value'
            '\tevent_id'
            '\tevent_id_hex'
            '\tevent_topology_name'
            '\tevent_component'
            '\tevent_name'
            '\tevent_severity'
            '\tevent_time'
            '\tevent_arguments_size'
            '\tevent_arguments'
            '\tpayload'
            '\n')

    def print_record(self, record):
        packet = record.packet
        payload = record.packet.payload
        sys.stdout.write(
            f'{record_index}'
            f'\t{record.offset}'
            f'\t{record.packet_size}'
            f'\t{packet.type.name}'
            f'\t{packet.type.value}')
        if record.packet.type == Packet.Type.TELEM:
            channel = (
                self._d
                and self._d.channels_by_id.get(payload.id.value, None)
            )
            sys.stdout.write(
                f'\t{payload.time}'
                f'\t{payload.id}'
                f'\t{payload.id:#x}'
                f'\t{getattr(channel, "topology_name", "")}'
                f'\t{getattr(channel, "component", "")}'
                f'\t{getattr(channel, "name", "")}'
                f'\t{payload.time}'
                f'\t{len(payload.value)}'
                f'\t{payload.value.data.hex() if len(payload.value) else ""}'
                '\t\t\t\t\t\t\t\t\t\t')
        elif record.packet.type == Packet.Type.LOG:
            event = self._d and self._d.events_by_id.get(payload.id.value, None)
            sys.stdout.write(
                f'\t{payload.time}'
                '\t\t\t\t\t\t\t\t'
                f'\t{payload.id}'
                f'\t{payload.id:#x}'
                f'\t{getattr(event, "topology_name", "")}'
                f'\t{getattr(event, "component", "")}'
                f'\t{getattr(event, "name", "")}'
                f'\t{getattr(event, "severity_str", "")}'
                f'\t{payload.time}'
                f'\t{len(payload.arguments)}'
                f'\t{payload.arguments.data.hex() if len(payload.arguments) else ""}'
                '\t')
        else:
            sys.stdout.write(
                '\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'
                f'\t{payload.data.hex()}')
        sys.stdout.write('\n')

    def print_footer(self):
        pass


class VnlogPrinter():

    def __init__(self, fprime_dict=None):
        self._d = fprime_dict

    def print_header(self):
        sys.stdout.write(
            '#record_index'
            '\trecord_offset'
            '\tpacket_size'
            '\tpacket_type_name'
            '\tpacket_type_value'
            '\tpacket_time'
            '\ttelem_id'
            '\ttelem_id_hex'
            '\ttelem_topology_name'
            '\ttelem_component'
            '\ttelem_name'
            '\ttelem_time'
            '\ttelem_value_size'
            '\ttelem_value'
            '\tevent_id'
            '\tevent_id_hex'
            '\tevent_topology_name'
            '\tevent_component'
            '\tevent_name'
            '\tevent_severity'
            '\tevent_time'
            '\tevent_arguments_size'
            '\tevent_arguments'
            '\tpayload'
            '\n')

    def print_record(self, record):
        packet = record.packet
        payload = record.packet.payload
        sys.stdout.write(
            f'{record_index}'
            f'\t{record.offset}'
            f'\t{record.packet_size}'
            f'\t{packet.type.name}'
            f'\t{packet.type.value}')
        if record.packet.type == Packet.Type.TELEM:
            channel = (
                self._d
                and self._d.channels_by_id.get(payload.id.value, None)
            )
            sys.stdout.write(
                f'\t{payload.time}'
                f'\t{payload.id}'
                f'\t{payload.id:#x}'
                f'\t{getattr(channel, "topology_name", "-")}'
                f'\t{getattr(channel, "component", "-")}'
                f'\t{getattr(channel, "name", "-")}'
                f'\t{payload.time}'
                f'\t{len(payload.value)}'
                f'\t{payload.value.data.hex() if len(payload.value) else "-"}'
                '\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-')
        elif record.packet.type == Packet.Type.LOG:
            event = self._d and self._d.events_by_id.get(payload.id.value, None)
            sys.stdout.write(
                f'\t{payload.time}'
                '\t-\t-\t-\t-\t-\t-\t-\t-'
                f'\t{payload.id}'
                f'\t{payload.id:#x}'
                f'\t{getattr(event, "topology_name", "-")}'
                f'\t{getattr(event, "component", "-")}'
                f'\t{getattr(event, "name", "-")}'
                f'\t{getattr(event, "severity_str", "-")}'
                f'\t{payload.time}'
                f'\t{len(payload.arguments)}'
                f'\t{payload.arguments.data.hex() if len(payload.arguments) else "-"}'
                '\t-')
        else:
            sys.stdout.write(
                '\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-'
                f'\t{payload.data.hex()}')
        sys.stdout.write('\n')

    def print_footer(self):
        pass


#### Main program --------------------------------------------------------------


if __name__ == '__main__':
    import argparse
    import pathlib
    import sys

    parser = argparse.ArgumentParser(description='''
        fprime-data-tool is a command line utility to read F Prime data in
        different formats and configurations and display them in different
        formats.  It can even work without a dictionary which is useful for
        sanity checking at the packet level.  With an F Prime FSW dictionary
        specified it can interpret the data.''')

    parser.add_argument(
        'istream',
        nargs='?',
        type=argparse.FileType('rb'),
        default=sys.stdin.buffer,
        help='''
            input ComLogger file (default: read from stdin)''')
    parser.add_argument(
        '-F', '--output-format',
        action='store',
        type=str,
        choices=('json', 'tsv', 'vnlog'),
        default='vnlog',
        help=f'''
            selects the output format; default is \'vnlog\'''')
    parser.add_argument(
        '-d', '--dictionary',
        type=pathlib.Path,
        default=None,
        required=False,
        help='''
            path to F Prime dictionary used to interpret packet contents;
            default is to use no dictionary and display packet contents as
            binary blobs''')
    parser.add_argument(
        '--record-type',
        type=str,
        default='ComLoggerRecord',
        help='''
            specifies the top-level type to parse; the parser will treat the
            input as a concatenated sequence of the specified type; for
            ComLogger logs use \'ComLoggerRecord\'; for fprime-gds recv.bin
            logs use \'FprimeGdsRecord\'; default is \'ComLoggerRecord\';
            typical choices are \'ComLoggerRecord\' and \'FprimeGdsRecord\' but
            can be any type defined with a decode class function; however if
            you choose a type other than \'ComLoggerRecord\' and
            \'FprimeGdsRecord\' then the output format will revert to JSON;
            types available: {}; '''.format(
                ', '.join(
                    f"'{name}'"
                    for name
                    in list(fp_types.keys()) + list(fp_types_custom.keys()))))

    for name, default in fprime_configurable_flags:
        parser.add_argument(
            f'--{name}',
            metavar='BOOL',
            dest=name,
            action='store',
            type=bool,
            default=default,
            help=f'''
                sets the F Prime configuration for {name}; must be a Python
                truthy like 'True' or 'False'; default is \'{default}\'''')

    def FundamentalType(type_name):
        if type_name in fptypes_fundamental:
            return fptypes_fundamental[type_name]
        raise KeyError(f'Unknown fundamental_type name "{type_name}"')

    fundamental_types_list = ', '.join(
        "'" + name + "'"
        for name, _ in fundamental_type_specs)
    for name, default in fprime_configurable_types:
        parser.add_argument(
            f'--{name}',
            metavar='FUNDAMENTAL_TYPE',
            dest=name,
            action='store',
            type=FundamentalType,
            default=default,
            help=f'''
                sets the F Prime configuration for {name}; must be one of the
                following fundamental_types: {fundamental_types_list}; default
                is \'{default.__name__}\'''')

    args = parser.parse_args()

    # Apply configurable flags from CLI options
    for name, _ in fprime_configurable_flags:
        globals()[name] = getattr(args, name)

    # Apply configurable types from CLI options
    for name, _ in fprime_configurable_types:
        fp_types[name] = getattr(args, name)
        globals()[name] = getattr(args, name)

    fprime_dict = args.dictionary and FprimeDictionary(args.dictionary)

    record_type = None
    record_type = fp_types.get(args.record_type, record_type)
    record_type = fp_types_custom.get(args.record_type, record_type)

    if record_type is not ComLoggerRecord and \
            record_type is not FprimeGdsRecord:
        sys.stderr.write(
            f'WARNING: Record type "{record_type.__name__}" is not either '
            '"ComLoggerRecord" or "FprimeGdsRecord" so forcing use of JSON '
            'printer\n')
        args.output_format = 'json'

    if args.output_format == 'json':
        printer = JsonPrinter(fprime_dict)
    elif args.output_format == 'tsv':
        printer = TsvPrinter(fprime_dict)
    elif args.output_format == 'vnlog':
        printer = VnlogPrinter(fprime_dict)
    else:
        raise KeyError(f'Unknown printer specified: "{args.output_format}"')

    printer.print_header()

    try:
        record_index = 0
        while True:
            record = record_type.decode(args.istream)
            printer.print_record(record)
            record_index += 1
    except BrokenPipeError:
        pass

    printer.print_footer()
